{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bffaafc",
   "metadata": {},
   "source": [
    "**Pr√°ctica Integrada: Pipeline de Preprocesamiento para An√°lisis de Feedback en E-Commerce**  \n",
    "**Contexto Empresarial Real:**  \n",
    "Eres parte del equipo de NLP de **MarketMind**, una empresa de e-commerce que analiza millones de comentarios de clientes (ingl√©s/espa√±ol) y tweets para detectar tendencias de productos. **Problema actual:** El modelo GPT-4 fine-tuned genera res√∫menes err√≥neos porque el texto crudo contiene URLs, precios, y emoticones mal normalizados.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Fase 1: Limpieza Contextual de Texto**  \n",
    "**Objetivo:** Crear una funci√≥n que procese texto crudo preservando informaci√≥n cr√≠tica para an√°lisis comercial.  \n",
    "\n",
    "#### **Datos de Entrada:**  \n",
    "\n",
    "Archivo -> validation_samples.json\n",
    "\n",
    "#### **Requisitos:**  \n",
    "1. **Eliminar:**  \n",
    "   - URLs, handles de usuario (@MariaP), y signos de puntuaci√≥n *excepto* `!`, `?`, `%`, `$`, `/`.  \n",
    "   - Par√©ntesis `()` y corchetes `[]`.  \n",
    "2. **Preservar:**  \n",
    "   - Emoticones (üòÉ, üî•), hashtags (#ModaDeportiva2023), y formatos comerciales (`2x`, `$99.99`).  \n",
    "   - Fechas (`30/11/2023`), horas (`18:30`), y porcentajes (`15%`).  \n",
    "3. **Normalizar:**  \n",
    "   - Unificar espacios m√∫ltiples y saltos de l√≠nea.  \n",
    "\n",
    "#### **Pistas de Implementaci√≥n:**  \n",
    "- Usar regex con grupos capturadores para fechas (`\\b\\d{2}/\\d{2}/\\d{4}\\b`).  \n",
    "- Para emoticones, usar la librer√≠a `emoji` (no eliminar üö´‚Üí ‚úÖ).  \n",
    "- Preservar `$`, `%`, y `/` solo si est√°n adyacentes a n√∫meros: `\\$?\\d+(\\.\\d+)?%?`.  \n",
    "\n",
    "#### **Verificaci√≥n:**  \n",
    "El texto procesado debe quedar:  \n",
    "```  \n",
    "üî• OFERTA Compre 2x zapatos Nike a $99.99 antes $150 üëü  \n",
    "V√°lido hasta el 30/11/2023 Atenci√≥n ¬øEnv√≠o gratis üòÉ #ModaDeportiva2023  \n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757face5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Verificaci√≥n Aleatoria ==\n",
      "\n",
      "Texto original:\n",
      "Best headphones ever! Bought for 129.95 USD on 11/11/2023. üéß\n",
      "\n",
      "Texto limpio:\n",
      "Best headphones ever! Bought for 129 95 USD on 11 / 11 / 2023 üéß\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import emoji\n",
    "import random\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Funci√≥n de limpieza de texto para an√°lisis de feedback en e-commerce.\n",
    "    \n",
    "    Par√°metros:\n",
    "    text (str): Texto a limpiar\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto limpio y normalizado\n",
    "    \"\"\"\n",
    "    # 1. Identificar y marcar elementos a preservar\n",
    "    \n",
    "    # Patrones para elementos a preservar\n",
    "    patterns_to_preserve = [\n",
    "        # Hashtags\n",
    "        (r'(#\\w+)', r' \\1 '),\n",
    "        \n",
    "        # Fechas en formato DD/MM/YYYY o YYYY-MM-DD\n",
    "        (r'(\\b\\d{2}/\\d{2}/\\d{4}\\b|\\b\\d{4}-\\d{2}-\\d{2}\\b)', r' \\1 '),\n",
    "        \n",
    "        # Horas en formato HH:MM\n",
    "        (r'(\\b\\d{1,2}:\\d{2}\\b)', r' \\1 '),\n",
    "        \n",
    "        # Formatos comerciales: 2x, $99.99, 15%, etc.\n",
    "        (r'(\\b\\d+x\\b)', r' \\1 '),  # Preservar formatos como 2x\n",
    "        (r'(\\$?\\d+(\\.\\d+)?(‚Ç¨|USD)?)', r' \\1 '),  # Preservar precios\n",
    "        (r'(\\d+(\\.\\d+)?%)', r' \\1 ')  # Preservar porcentajes\n",
    "    ]\n",
    "    \n",
    "    # Aplicar patrones de preservaci√≥n\n",
    "    for pattern, replacement in patterns_to_preserve:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    # 2. Eliminar elementos no deseados\n",
    "    \n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    \n",
    "    # Eliminar handles de usuario (@usuario)\n",
    "    text = re.sub(r'@\\w+', ' ', text)\n",
    "    \n",
    "    # Eliminar par√©ntesis y corchetes pero preservar su contenido\n",
    "    text = re.sub(r'[\\(\\)\\[\\]{}]', ' ', text)\n",
    "    \n",
    "    # 3. Crear una lista de caracteres a mantener (emojis y puntuaci√≥n permitida)\n",
    "    chars_to_keep = ['!', '?', '%', '$', '/', '‚Ç¨']\n",
    "    \n",
    "    # 4. Procesar el texto caracter por caracter\n",
    "    result = []\n",
    "    for char in text:\n",
    "        # Mantener emojis\n",
    "        if char in emoji.EMOJI_DATA:\n",
    "            result.append(char)\n",
    "        # Mantener puntuaci√≥n permitida\n",
    "        elif char in chars_to_keep:\n",
    "            result.append(char)\n",
    "        # Mantener letras, n√∫meros y espacios\n",
    "        elif char.isalnum() or char.isspace():\n",
    "            result.append(char)\n",
    "        # Reemplazar otra puntuaci√≥n con espacio\n",
    "        else:\n",
    "            result.append(' ')\n",
    "    \n",
    "    # 5. Normalizar espacios m√∫ltiples y saltos de l√≠nea\n",
    "    processed_text = ''.join(result)\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text).strip()\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Cargar los datos de ejemplo para pruebas\n",
    "with open('validation_samples.json', 'r', encoding='utf-8') as f:\n",
    "    samples = json.load(f)\n",
    "\n",
    "# Seleccionar un ejemplo aleatorio para verificaci√≥n\n",
    "random_sample = random.choice(samples)\n",
    "ejemplo = random_sample['input']\n",
    "\n",
    "print(\"== Verificaci√≥n Aleatoria ==\")\n",
    "print(\"\\nTexto original:\")\n",
    "print(ejemplo)\n",
    "print(\"\\nTexto limpio:\")\n",
    "print(clean_text(ejemplo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea565bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d75c8",
   "metadata": {},
   "source": [
    "### **Fase 2: Normalizaci√≥n de N√∫meros y Unidades**  \n",
    "**Objetivo:** Reemplazar n√∫meros gen√©ricos pero preservar formatos clave para el modelo de precios.  \n",
    "\n",
    "#### **Requisitos:**  \n",
    "1. **Reemplazar:**  \n",
    "   - N√∫meros sueltos (ej. `150` ‚Üí `<NUM>`) excepto si est√°n en fechas, precios, o unidades (`2x`).  \n",
    "2. **Convertir:**  \n",
    "   - Fechas a formato est√°ndar ISO: `30/11/2023` ‚Üí `2023-11-30`.  \n",
    "   - Unidades de venta al por menor: `2x` ‚Üí `2_unidades`, `3kg` ‚Üí `3_kg`.  \n",
    "3. **Procesar Monedas:**  \n",
    "   - `$99.99` ‚Üí `<USD>99.99`, `150‚Ç¨` ‚Üí `<EUR>150`.  \n",
    "\n",
    "#### **Pistas de Implementaci√≥n:**  \n",
    "- Usar `dateparser` para normalizar fechas en m√∫ltiples formatos (ej. `marzo 15, 2023` ‚Üí `2023-03-15`).  \n",
    "- Para unidades: `r'\\b(\\d+)(x|kg|ml)\\b'` ‚Üí `\\1_\\2`.  \n",
    "- Diferenciar `$100` (precio) de `100$` (com√∫n en espa√±ol) usando lookbehinds en regex.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73b1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Verificaci√≥n Pipeline Fase 2 ==\n",
      "\n",
      "Texto original:\n",
      "I love my new iPhone 12! üòç Battery life is amazing. Bought it at 799‚Ç¨ from https://apple.com. #TechReview\n",
      "\n",
      "Texto limpio:\n",
      "I love my new iPhone 12 ! üòç Battery life is amazing Bought it at 799‚Ç¨ from TechReview\n",
      "\n",
      "Texto normalizado:\n",
      "I love my new iPhone <NUM> ! üòç Battery life is amazing Bought it at <EUR>799 from TechReview\n",
      "\n",
      "== Verificaci√≥n con Ejemplo Espec√≠fico ==\n",
      "\n",
      "Texto original:\n",
      "üî•¬°OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) üëü. ¬°V√°lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. Atenci√≥n @MariaP: ¬øEnv√≠o gratis? üòÉ #ModaDeportiva2023.\n",
      "\n",
      "Texto normalizado (pipeline completo):\n",
      "üî• OFERTA! Compre <NUM> x zapatos Nike a <USD>99 <NUM> antes <USD>150 üëü V√°lido hasta el <NUM> / <NUM> / <NUM> ! Visita Atenci√≥n Env√≠o gratis? üòÉ ModaDeportiva <NUM>\n"
     ]
    }
   ],
   "source": [
    "import dateparser\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Funci√≥n de normalizaci√≥n de n√∫meros y unidades para an√°lisis de feedback en e-commerce.\n",
    "    \n",
    "    Par√°metros:\n",
    "    text (str): Texto a normalizar (previamente limpiado)\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto normalizado\n",
    "    \"\"\"\n",
    "    # 1. Normalizar fechas a formato ISO (YYYY-MM-DD)\n",
    "    # Buscar fechas en formatos comunes (DD/MM/YYYY, YYYY-MM-DD, etc.)\n",
    "    date_pattern = r'\\b(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}-\\d{2}-\\d{2})\\b'\n",
    "    \n",
    "    def normalize_date(match):\n",
    "        date_str = match.group(1)\n",
    "        try:\n",
    "            parsed_date = dateparser.parse(date_str)\n",
    "            if parsed_date:\n",
    "                return parsed_date.strftime('%Y-%m-%d')\n",
    "            return date_str\n",
    "        except:\n",
    "            return date_str\n",
    "    \n",
    "    text = re.sub(date_pattern, lambda m: normalize_date(m), text)\n",
    "    \n",
    "    # 2. Normalizar unidades de venta (2x -> 2_unidades, 3kg -> 3_kg, etc.)\n",
    "    # Patrones para diferentes tipos de unidades\n",
    "    unit_patterns = [\n",
    "        # Patr√≥n para formatos como \"2x\"\n",
    "        (r'\\b(\\d+)x\\b', r'\\1_unidades'),\n",
    "        \n",
    "        # Patr√≥n para unidades de peso/volumen\n",
    "        (r'\\b(\\d+)(kg|g|ml|l)\\b', r'\\1_\\2')\n",
    "    ]\n",
    "    \n",
    "    for pattern, replacement in unit_patterns:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    # 3. Procesar monedas\n",
    "    # USD: $99.99 -> <USD>99.99\n",
    "    text = re.sub(r'\\$\\s*(\\d+(?:\\.\\d+)?)', r'<USD>\\1', text)\n",
    "    \n",
    "    # EUR: 150‚Ç¨ -> <EUR>150\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*‚Ç¨', r'<EUR>\\1', text)\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*EUR', r'<EUR>\\1', text)\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*euros?', r'<EUR>\\1', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # USD texto: 99.99 USD -> <USD>99.99\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*USD', r'<USD>\\1', text)\n",
    "    \n",
    "    # 4. Reemplazar n√∫meros sueltos (que no sean parte de fechas, precios o unidades)\n",
    "    # Primero identificamos patrones que NO deben ser reemplazados\n",
    "    def replace_isolated_numbers(text):\n",
    "        # Tokenizamos primero para tratar cada palabra\n",
    "        tokens = text.split()\n",
    "        result = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            # Saltar si ya est√° procesado como moneda, unidad o fecha\n",
    "            if (re.match(r'<(USD|EUR)>\\d+(\\.\\d+)?', token) or \n",
    "                re.match(r'\\d+_\\w+', token) or \n",
    "                re.match(r'\\d{4}-\\d{2}-\\d{2}', token) or \n",
    "                re.match(r'#\\w+', token)):\n",
    "                result.append(token)\n",
    "            # Reemplazar n√∫meros sueltos\n",
    "            elif token.isdigit() or re.match(r'^\\d+\\.\\d+$', token):\n",
    "                result.append('<NUM>')\n",
    "            else:\n",
    "                result.append(token)\n",
    "                \n",
    "        return ' '.join(result)\n",
    "    \n",
    "    text = replace_isolated_numbers(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Procesamiento en pipeline: limpieza + normalizaci√≥n\n",
    "def process_text(text):\n",
    "    \"\"\"Aplica el pipeline completo de procesamiento de texto: limpieza + normalizaci√≥n.\n",
    "    \n",
    "    Par√°metros:\n",
    "    text (str): Texto crudo a procesar\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto completamente limpio y normalizado\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    normalized = normalize_text(cleaned)\n",
    "    return normalized\n",
    "\n",
    "# Seleccionar un ejemplo aleatorio para verificaci√≥n\n",
    "random_sample = random.choice(samples)\n",
    "ejemplo = random_sample['input']\n",
    "\n",
    "print(\"== Verificaci√≥n Pipeline Fase 2 ==\\n\")\n",
    "print(\"Texto original:\")\n",
    "print(ejemplo)\n",
    "print(\"\\nTexto limpio:\")\n",
    "cleaned = clean_text(ejemplo)\n",
    "print(cleaned)\n",
    "print(\"\\nTexto normalizado:\")\n",
    "print(normalize_text(cleaned))\n",
    "\n",
    "# Ejemplo espec√≠fico para verificar contra los requisitos\n",
    "ejemplo_especifico = \"üî•¬°OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) üëü. ¬°V√°lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. Atenci√≥n @MariaP: ¬øEnv√≠o gratis? üòÉ #ModaDeportiva2023.\"\n",
    "print(\"\\n== Verificaci√≥n con Ejemplo Espec√≠fico ==\\n\")\n",
    "print(\"Texto original:\")\n",
    "print(ejemplo_especifico)\n",
    "print(\"\\nTexto normalizado (pipeline completo):\")\n",
    "print(process_text(ejemplo_especifico))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b3a32",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd0e22",
   "metadata": {},
   "source": [
    "### **Fase 3: Normalizaci√≥n de May√∫sculas con Reconocimiento de Entidades**  \n",
    "**Objetivo:** Convertir a min√∫sculas sin perder marcas comerciales o nombres de productos.  \n",
    "\n",
    "#### **Requisitos:**  \n",
    "1. **Preservar en may√∫sculas:**  \n",
    "   - Nombres de marcas (`Nike`, `iPhone`).  \n",
    "   - Hashtags (`#ModaDeportiva2023`).  \n",
    "   - Entidades geopol√≠ticas (`Madrid`, `M√©xico`).  \n",
    "2. **Convertir a min√∫sculas:**  \n",
    "   - Verbo \"compre\" ‚Üí \"compre\", \"Zapatos\" ‚Üí \"zapatos\".  \n",
    "\n",
    "#### **Pistas de Implementaci√≥n:**  \n",
    "- Usar `spaCy` con modelo `es_core_news_lg` para detectar entidades (ORG, LOC, PRODUCT).  \n",
    "- Para marcas no reconocidas por spaCy (ej. `Zara`), cargar un diccionario personalizado desde un CSV.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2a2eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Verificaci√≥n Pipeline Completo ==\n",
      "\n",
      "Texto original:\n",
      "üî•¬°OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) üëü. ¬°V√°lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. Atenci√≥n @MariaP: ¬øEnv√≠o gratis? üòÉ #ModaDeportiva2023.\n",
      "\n",
      "Texto limpio (Fase 1):\n",
      "üî• OFERTA! Compre 2 x zapatos Nike a $99 99 antes $150 üëü V√°lido hasta el 30 / 11 / 2023 ! Visita Atenci√≥n Env√≠o gratis? üòÉ ModaDeportiva 2023\n",
      "\n",
      "Texto normalizado (Fase 2):\n",
      "üî• OFERTA! Compre <NUM> x zapatos Nike a <USD>99 <NUM> antes <USD>150 üëü V√°lido hasta el <NUM> / <NUM> / <NUM> ! Visita Atenci√≥n Env√≠o gratis? üòÉ ModaDeportiva <NUM>\n",
      "\n",
      "Texto con may√∫sculas normalizadas (Fase 3):\n",
      "üî• oferta! Compre <num> x zapatos Nike a <usd>99 <num> antes <USD>150 üëü v√°lido hasta el <num> / <num> / <num> ! visita atenci√≥n env√≠o gratis? üòÉ modadeportiva <num>\n",
      "\n",
      "Texto procesado (Pipeline completo):\n",
      "üî• oferta! Compre <num> x zapatos Nike a <usd>99 <num> antes <USD>150 üëü v√°lido hasta el <num> / <num> / <num> ! visita atenci√≥n env√≠o gratis? üòÉ modadeportiva <num>\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar modelos de spaCy para espa√±ol e ingl√©s\n",
    "try:\n",
    "    nlp_es = spacy.load(\"es_core_news_md\")\n",
    "    nlp_en = spacy.load(\"en_core_web_md\")\n",
    "except OSError:\n",
    "    print(\"Error: Los modelos de spaCy no est√°n instalados.\")\n",
    "    print(\"Necesitas ejecutar la celda anterior para descargarlos.\")\n",
    "\n",
    "# Diccionario de marcas personalizadas que queremos preservar\n",
    "# Podr√≠a ser cargado desde un CSV en un caso real\n",
    "marcas_personalizadas = [\n",
    "    \"Nike\", \"Adidas\", \"Zara\", \"H&M\", \"Apple\", \"Samsung\", \"iPhone\", \n",
    "    \"Canon\", \"Sony\", \"Xiaomi\", \"MarketMind\"\n",
    "]\n",
    "\n",
    "def normalize_case(text):\n",
    "    \"\"\"Funci√≥n para normalizar may√∫sculas preservando nombres de marcas, productos y entidades geopol√≠ticas.\n",
    "    \n",
    "    Par√°metros:\n",
    "    text (str): Texto a normalizar (previamente limpiado y con n√∫meros normalizados)\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto con may√∫sculas normalizadas\n",
    "    \"\"\"\n",
    "    # Primero detectamos el idioma para usar el modelo adecuado\n",
    "    # Esta es una simplificaci√≥n, para una aplicaci√≥n real se usar√≠a\n",
    "    # un detector de idioma m√°s robusto\n",
    "    if any(word in text.lower() for word in ['el', 'la', 'los', 'las', 'en', 'con', 'para']):\n",
    "        nlp = nlp_es\n",
    "    else:\n",
    "        nlp = nlp_en\n",
    "        \n",
    "    # Tokenizamos el texto\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Identificamos las entidades que queremos preservar\n",
    "    entity_spans = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"PRODUCT\", \"LOC\", \"GPE\"]:\n",
    "            entity_spans.append((ent.start_char, ent.end_char, ent.text))\n",
    "            \n",
    "    # Identificamos hashtags y menciones\n",
    "    tokens = text.split()\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.startswith(\"#\"):\n",
    "            start_idx = text.find(token)\n",
    "            if start_idx >= 0:\n",
    "                entity_spans.append((start_idx, start_idx + len(token), token))\n",
    "    \n",
    "    # Buscamos marcas personalizadas en el texto\n",
    "    for marca in marcas_personalizadas:\n",
    "        start = 0\n",
    "        while True:\n",
    "            start_idx = text.lower().find(marca.lower(), start)\n",
    "            if start_idx < 0:\n",
    "                break\n",
    "            entity_spans.append((start_idx, start_idx + len(marca), marca))\n",
    "            start = start_idx + len(marca)\n",
    "            \n",
    "    # Convertir todo a min√∫sculas primero\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Reconstruir el texto preservando las entidades identificadas\n",
    "    result = list(text_lower)\n",
    "    for start, end, original in sorted(entity_spans, key=lambda x: x[0]):\n",
    "        for i in range(start, end):\n",
    "            if i < len(result):\n",
    "                result[i] = text[i]\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "# Funci√≥n para el pipeline completo: limpieza + normalizaci√≥n + casos\n",
    "def process_text_full(text):\n",
    "    \"\"\"Aplica el pipeline completo de procesamiento de texto: \n",
    "    limpieza + normalizaci√≥n de n√∫meros y unidades + normalizaci√≥n de may√∫sculas.\n",
    "    \n",
    "    Par√°metros:\n",
    "    text (str): Texto crudo a procesar\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto completamente procesado\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    normalized = normalize_text(cleaned)\n",
    "    case_normalized = normalize_case(normalized)\n",
    "    return case_normalized\n",
    "\n",
    "# Verificar con el ejemplo espec√≠fico\n",
    "ejemplo_especifico = \"üî•¬°OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) üëü. ¬°V√°lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. Atenci√≥n @MariaP: ¬øEnv√≠o gratis? üòÉ #ModaDeportiva2023.\"\n",
    "print(\"== Verificaci√≥n Pipeline Completo ==\\n\")\n",
    "print(\"Texto original:\")\n",
    "print(ejemplo_especifico)\n",
    "\n",
    "print(\"\\nTexto limpio (Fase 1):\")\n",
    "cleaned = clean_text(ejemplo_especifico)\n",
    "print(cleaned)\n",
    "\n",
    "print(\"\\nTexto normalizado (Fase 2):\")\n",
    "normalized = normalize_text(cleaned)\n",
    "print(normalized)\n",
    "\n",
    "print(\"\\nTexto con may√∫sculas normalizadas (Fase 3):\")\n",
    "case_normalized = normalize_case(normalized)\n",
    "print(case_normalized)\n",
    "\n",
    "print(\"\\nTexto procesado (Pipeline completo):\")\n",
    "print(process_text_full(ejemplo_especifico))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb1c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplo 1 ===\n",
      "Texto original:\n",
      "¬øD√≥nde est√° mi pedido? N√∫mero de orden: #456DEF. Llevan 7 d√≠as sin actualizar.\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "d√≥nde est√° mi pedido? n√∫mero de orden <num> def llevan <num> d√≠as sin actualizar\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 2 ===\n",
      "Texto original:\n",
      "Best headphones ever! Bought for 129.95 USD on 11/11/2023. üéß\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "best headphones ever! bought for <num> <usd>95 on <num> / <num> / <num> üéß\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 3 ===\n",
      "Texto original:\n",
      "Achieved my fitness goal with this! Purchased 1x treadmill at $799.99. üèÉ‚Äç‚ôÇÔ∏è\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "achieved my fitness goal with this! purchased <num> x treadmill at <usd>799 <num> üèÉ ‚ôÇ\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 4 ===\n",
      "Texto original:\n",
      "Me encanta este producto! Calidad superior, pero 150‚Ç¨ es caro. Link: http://ecomerce.test/item123. üëç #Review\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "me encanta este producto! calidad superior pero <EUR>150 es caro Link <num> üëç Review\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 5 ===\n",
      "Texto original:\n",
      "Slow shipping to Madrid. Expected in 10 days, arrived in 15. üòï\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "slow shipping to Madrid expected in <num> days arrived in <num> üòï\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Probemos con algunos ejemplos aleatorios para verificar el funcionamiento completo del pipeline\n",
    "for i in range(5):\n",
    "    random_sample = random.choice(samples)\n",
    "    ejemplo = random_sample['input']\n",
    "    \n",
    "    print(f\"\\n=== Ejemplo {i+1} ===\")\n",
    "    print(\"Texto original:\")\n",
    "    print(ejemplo)\n",
    "    print(\"\\nTexto procesado (pipeline completo):\")\n",
    "    print(process_text_full(ejemplo))\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvWSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
