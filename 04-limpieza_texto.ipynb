{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bffaafc",
   "metadata": {},
   "source": [
    "**PrÃ¡ctica Integrada: Pipeline de Preprocesamiento para AnÃ¡lisis de Feedback en E-Commerce**  \n",
    "**Contexto Empresarial Real:**  \n",
    "Eres parte del equipo de NLP de **MarketMind**, una empresa de e-commerce que analiza millones de comentarios de clientes (inglÃ©s/espaÃ±ol) y tweets para detectar tendencias de productos. **Problema actual:** El modelo GPT-4 fine-tuned genera resÃºmenes errÃ³neos porque el texto crudo contiene URLs, precios, y emoticones mal normalizados.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Fase 1: Limpieza Contextual de Texto**  \n",
    "**Objetivo:** Crear una funciÃ³n que procese texto crudo preservando informaciÃ³n crÃ­tica para anÃ¡lisis comercial.  \n",
    "\n",
    "#### **Datos de Entrada:**  \n",
    "\n",
    "Archivo -> validation_samples.json\n",
    "\n",
    "#### **Requisitos:**  \n",
    "1. **Eliminar:**  \n",
    "   - URLs, handles de usuario (@MariaP), y signos de puntuaciÃ³n *excepto* `!`, `?`, `%`, `$`, `/`.  \n",
    "   - ParÃ©ntesis `()` y corchetes `[]`.  \n",
    "2. **Preservar:**  \n",
    "   - Emoticones (ğŸ˜ƒ, ğŸ”¥), hashtags (#ModaDeportiva2023), y formatos comerciales (`2x`, `$99.99`).  \n",
    "   - Fechas (`30/11/2023`), horas (`18:30`), y porcentajes (`15%`).  \n",
    "3. **Normalizar:**  \n",
    "   - Unificar espacios mÃºltiples y saltos de lÃ­nea.  \n",
    "\n",
    "#### **Pistas de ImplementaciÃ³n:**  \n",
    "- Usar regex con grupos capturadores para fechas (`\\b\\d{2}/\\d{2}/\\d{4}\\b`).  \n",
    "- Para emoticones, usar la librerÃ­a `emoji` (no eliminar ğŸš«â†’ âœ…).  \n",
    "- Preservar `$`, `%`, y `/` solo si estÃ¡n adyacentes a nÃºmeros: `\\$?\\d+(\\.\\d+)?%?`.  \n",
    "\n",
    "#### **VerificaciÃ³n:**  \n",
    "El texto procesado debe quedar:  \n",
    "```  \n",
    "ğŸ”¥ OFERTA Compre 2x zapatos Nike a $99.99 antes $150 ğŸ‘Ÿ  \n",
    "VÃ¡lido hasta el 30/11/2023 AtenciÃ³n Â¿EnvÃ­o gratis ğŸ˜ƒ #ModaDeportiva2023  \n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757face5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== VerificaciÃ³n Aleatoria ==\n",
      "\n",
      "Texto original:\n",
      "Best headphones ever! Bought for 129.95 USD on 11/11/2023. ğŸ§\n",
      "\n",
      "Texto limpio:\n",
      "Best headphones ever! Bought for 129 95 USD on 11 / 11 / 2023 ğŸ§\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import emoji\n",
    "import random\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"FunciÃ³n de limpieza de texto para anÃ¡lisis de feedback en e-commerce.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "    text (str): Texto a limpiar\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto limpio y normalizado\n",
    "    \"\"\"\n",
    "    # 1. Identificar y marcar elementos a preservar\n",
    "    \n",
    "    # Patrones para elementos a preservar\n",
    "    patterns_to_preserve = [\n",
    "        # Hashtags\n",
    "        (r'(#\\w+)', r' \\1 '),\n",
    "        \n",
    "        # Fechas en formato DD/MM/YYYY o YYYY-MM-DD\n",
    "        (r'(\\b\\d{2}/\\d{2}/\\d{4}\\b|\\b\\d{4}-\\d{2}-\\d{2}\\b)', r' \\1 '),\n",
    "        \n",
    "        # Horas en formato HH:MM\n",
    "        (r'(\\b\\d{1,2}:\\d{2}\\b)', r' \\1 '),\n",
    "        \n",
    "        # Formatos comerciales: 2x, $99.99, 15%, etc.\n",
    "        (r'(\\b\\d+x\\b)', r' \\1 '),  # Preservar formatos como 2x\n",
    "        (r'(\\$?\\d+(\\.\\d+)?(â‚¬|USD)?)', r' \\1 '),  # Preservar precios\n",
    "        (r'(\\d+(\\.\\d+)?%)', r' \\1 ')  # Preservar porcentajes\n",
    "    ]\n",
    "    \n",
    "    # Aplicar patrones de preservaciÃ³n\n",
    "    for pattern, replacement in patterns_to_preserve:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    # 2. Eliminar elementos no deseados\n",
    "    \n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    \n",
    "    # Eliminar handles de usuario (@usuario)\n",
    "    text = re.sub(r'@\\w+', ' ', text)\n",
    "    \n",
    "    # Eliminar parÃ©ntesis y corchetes pero preservar su contenido\n",
    "    text = re.sub(r'[\\(\\)\\[\\]{}]', ' ', text)\n",
    "    \n",
    "    # 3. Crear una lista de caracteres a mantener (emojis y puntuaciÃ³n permitida)\n",
    "    chars_to_keep = ['!', '?', '%', '$', '/', 'â‚¬']\n",
    "    \n",
    "    # 4. Procesar el texto caracter por caracter\n",
    "    result = []\n",
    "    for char in text:\n",
    "        # Mantener emojis\n",
    "        if char in emoji.EMOJI_DATA:\n",
    "            result.append(char)\n",
    "        # Mantener puntuaciÃ³n permitida\n",
    "        elif char in chars_to_keep:\n",
    "            result.append(char)\n",
    "        # Mantener letras, nÃºmeros y espacios\n",
    "        elif char.isalnum() or char.isspace():\n",
    "            result.append(char)\n",
    "        # Reemplazar otra puntuaciÃ³n con espacio\n",
    "        else:\n",
    "            result.append(' ')\n",
    "    \n",
    "    # 5. Normalizar espacios mÃºltiples y saltos de lÃ­nea\n",
    "    processed_text = ''.join(result)\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text).strip()\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Cargar los datos de ejemplo para pruebas\n",
    "with open('validation_samples.json', 'r', encoding='utf-8') as f:\n",
    "    samples = json.load(f)\n",
    "\n",
    "# Seleccionar un ejemplo aleatorio para verificaciÃ³n\n",
    "random_sample = random.choice(samples)\n",
    "ejemplo = random_sample['input']\n",
    "\n",
    "print(\"== VerificaciÃ³n Aleatoria ==\")\n",
    "print(\"\\nTexto original:\")\n",
    "print(ejemplo)\n",
    "print(\"\\nTexto limpio:\")\n",
    "print(clean_text(ejemplo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea565bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d75c8",
   "metadata": {},
   "source": [
    "### **Fase 2: NormalizaciÃ³n de NÃºmeros y Unidades**  \n",
    "**Objetivo:** Reemplazar nÃºmeros genÃ©ricos pero preservar formatos clave para el modelo de precios.  \n",
    "\n",
    "#### **Requisitos:**  \n",
    "1. **Reemplazar:**  \n",
    "   - NÃºmeros sueltos (ej. `150` â†’ `<NUM>`) excepto si estÃ¡n en fechas, precios, o unidades (`2x`).  \n",
    "2. **Convertir:**  \n",
    "   - Fechas a formato estÃ¡ndar ISO: `30/11/2023` â†’ `2023-11-30`.  \n",
    "   - Unidades de venta al por menor: `2x` â†’ `2_unidades`, `3kg` â†’ `3_kg`.  \n",
    "3. **Procesar Monedas:**  \n",
    "   - `$99.99` â†’ `<USD>99.99`, `150â‚¬` â†’ `<EUR>150`.  \n",
    "\n",
    "#### **Pistas de ImplementaciÃ³n:**  \n",
    "- Usar `dateparser` para normalizar fechas en mÃºltiples formatos (ej. `marzo 15, 2023` â†’ `2023-03-15`).  \n",
    "- Para unidades: `r'\\b(\\d+)(x|kg|ml)\\b'` â†’ `\\1_\\2`.  \n",
    "- Diferenciar `$100` (precio) de `100$` (comÃºn en espaÃ±ol) usando lookbehinds en regex.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73b1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== VerificaciÃ³n Pipeline Fase 2 ==\n",
      "\n",
      "Texto original:\n",
      "I love my new iPhone 12! ğŸ˜ Battery life is amazing. Bought it at 799â‚¬ from https://apple.com. #TechReview\n",
      "\n",
      "Texto limpio:\n",
      "I love my new iPhone 12 ! ğŸ˜ Battery life is amazing Bought it at 799â‚¬ from TechReview\n",
      "\n",
      "Texto normalizado:\n",
      "I love my new iPhone <NUM> ! ğŸ˜ Battery life is amazing Bought it at <EUR>799 from TechReview\n",
      "\n",
      "== VerificaciÃ³n con Ejemplo EspecÃ­fico ==\n",
      "\n",
      "Texto original:\n",
      "ğŸ”¥Â¡OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) ğŸ‘Ÿ. Â¡VÃ¡lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. AtenciÃ³n @MariaP: Â¿EnvÃ­o gratis? ğŸ˜ƒ #ModaDeportiva2023.\n",
      "\n",
      "Texto normalizado (pipeline completo):\n",
      "ğŸ”¥ OFERTA! Compre <NUM> x zapatos Nike a <USD>99 <NUM> antes <USD>150 ğŸ‘Ÿ VÃ¡lido hasta el <NUM> / <NUM> / <NUM> ! Visita AtenciÃ³n EnvÃ­o gratis? ğŸ˜ƒ ModaDeportiva <NUM>\n"
     ]
    }
   ],
   "source": [
    "import dateparser\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"FunciÃ³n de normalizaciÃ³n de nÃºmeros y unidades para anÃ¡lisis de feedback en e-commerce.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "    text (str): Texto a normalizar (previamente limpiado)\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto normalizado\n",
    "    \"\"\"\n",
    "    # 1. Normalizar fechas a formato ISO (YYYY-MM-DD)\n",
    "    # Buscar fechas en formatos comunes (DD/MM/YYYY, YYYY-MM-DD, etc.)\n",
    "    date_pattern = r'\\b(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}-\\d{2}-\\d{2})\\b'\n",
    "    \n",
    "    def normalize_date(match):\n",
    "        date_str = match.group(1)\n",
    "        try:\n",
    "            parsed_date = dateparser.parse(date_str)\n",
    "            if parsed_date:\n",
    "                return parsed_date.strftime('%Y-%m-%d')\n",
    "            return date_str\n",
    "        except:\n",
    "            return date_str\n",
    "    \n",
    "    text = re.sub(date_pattern, lambda m: normalize_date(m), text)\n",
    "    \n",
    "    # 2. Normalizar unidades de venta (2x -> 2_unidades, 3kg -> 3_kg, etc.)\n",
    "    # Patrones para diferentes tipos de unidades\n",
    "    unit_patterns = [\n",
    "        # PatrÃ³n para formatos como \"2x\"\n",
    "        (r'\\b(\\d+)x\\b', r'\\1_unidades'),\n",
    "        \n",
    "        # PatrÃ³n para unidades de peso/volumen\n",
    "        (r'\\b(\\d+)(kg|g|ml|l)\\b', r'\\1_\\2')\n",
    "    ]\n",
    "    \n",
    "    for pattern, replacement in unit_patterns:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    \n",
    "    # 3. Procesar monedas\n",
    "    # USD: $99.99 -> <USD>99.99\n",
    "    text = re.sub(r'\\$\\s*(\\d+(?:\\.\\d+)?)', r'<USD>\\1', text)\n",
    "    \n",
    "    # EUR: 150â‚¬ -> <EUR>150\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*â‚¬', r'<EUR>\\1', text)\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*EUR', r'<EUR>\\1', text)\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*euros?', r'<EUR>\\1', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # USD texto: 99.99 USD -> <USD>99.99\n",
    "    text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*USD', r'<USD>\\1', text)\n",
    "    \n",
    "    # 4. Reemplazar nÃºmeros sueltos (que no sean parte de fechas, precios o unidades)\n",
    "    # Primero identificamos patrones que NO deben ser reemplazados\n",
    "    def replace_isolated_numbers(text):\n",
    "        # Tokenizamos primero para tratar cada palabra\n",
    "        tokens = text.split()\n",
    "        result = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            # Saltar si ya estÃ¡ procesado como moneda, unidad o fecha\n",
    "            if (re.match(r'<(USD|EUR)>\\d+(\\.\\d+)?', token) or \n",
    "                re.match(r'\\d+_\\w+', token) or \n",
    "                re.match(r'\\d{4}-\\d{2}-\\d{2}', token) or \n",
    "                re.match(r'#\\w+', token)):\n",
    "                result.append(token)\n",
    "            # Reemplazar nÃºmeros sueltos\n",
    "            elif token.isdigit() or re.match(r'^\\d+\\.\\d+$', token):\n",
    "                result.append('<NUM>')\n",
    "            else:\n",
    "                result.append(token)\n",
    "                \n",
    "        return ' '.join(result)\n",
    "    \n",
    "    text = replace_isolated_numbers(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Procesamiento en pipeline: limpieza + normalizaciÃ³n\n",
    "def process_text(text):\n",
    "    \"\"\"Aplica el pipeline completo de procesamiento de texto: limpieza + normalizaciÃ³n.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "    text (str): Texto crudo a procesar\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto completamente limpio y normalizado\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    normalized = normalize_text(cleaned)\n",
    "    return normalized\n",
    "\n",
    "# Seleccionar un ejemplo aleatorio para verificaciÃ³n\n",
    "random_sample = random.choice(samples)\n",
    "ejemplo = random_sample['input']\n",
    "\n",
    "print(\"== VerificaciÃ³n Pipeline Fase 2 ==\\n\")\n",
    "print(\"Texto original:\")\n",
    "print(ejemplo)\n",
    "print(\"\\nTexto limpio:\")\n",
    "cleaned = clean_text(ejemplo)\n",
    "print(cleaned)\n",
    "print(\"\\nTexto normalizado:\")\n",
    "print(normalize_text(cleaned))\n",
    "\n",
    "# Ejemplo especÃ­fico para verificar contra los requisitos\n",
    "ejemplo_especifico = \"ğŸ”¥Â¡OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) ğŸ‘Ÿ. Â¡VÃ¡lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. AtenciÃ³n @MariaP: Â¿EnvÃ­o gratis? ğŸ˜ƒ #ModaDeportiva2023.\"\n",
    "print(\"\\n== VerificaciÃ³n con Ejemplo EspecÃ­fico ==\\n\")\n",
    "print(\"Texto original:\")\n",
    "print(ejemplo_especifico)\n",
    "print(\"\\nTexto normalizado (pipeline completo):\")\n",
    "print(process_text(ejemplo_especifico))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b3a32",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd0e22",
   "metadata": {},
   "source": [
    "### **Fase 3: NormalizaciÃ³n de MayÃºsculas con Reconocimiento de Entidades**  \n",
    "**Objetivo:** Convertir a minÃºsculas sin perder marcas comerciales o nombres de productos.  \n",
    "\n",
    "#### **Requisitos:**  \n",
    "1. **Preservar en mayÃºsculas:**  \n",
    "   - Nombres de marcas (`Nike`, `iPhone`).  \n",
    "   - Hashtags (`#ModaDeportiva2023`).  \n",
    "   - Entidades geopolÃ­ticas (`Madrid`, `MÃ©xico`).  \n",
    "2. **Convertir a minÃºsculas:**  \n",
    "   - Verbo \"compre\" â†’ \"compre\", \"Zapatos\" â†’ \"zapatos\".  \n",
    "\n",
    "#### **Pistas de ImplementaciÃ³n:**  \n",
    "- Usar `spaCy` con modelo `es_core_news_lg` para detectar entidades (ORG, LOC, PRODUCT).  \n",
    "- Para marcas no reconocidas por spaCy (ej. `Zara`), cargar un diccionario personalizado desde un CSV.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2a2eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== VerificaciÃ³n Pipeline Completo ==\n",
      "\n",
      "Texto original:\n",
      "ğŸ”¥Â¡OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) ğŸ‘Ÿ. Â¡VÃ¡lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. AtenciÃ³n @MariaP: Â¿EnvÃ­o gratis? ğŸ˜ƒ #ModaDeportiva2023.\n",
      "\n",
      "Texto limpio (Fase 1):\n",
      "ğŸ”¥ OFERTA! Compre 2 x zapatos Nike a $99 99 antes $150 ğŸ‘Ÿ VÃ¡lido hasta el 30 / 11 / 2023 ! Visita AtenciÃ³n EnvÃ­o gratis? ğŸ˜ƒ ModaDeportiva 2023\n",
      "\n",
      "Texto normalizado (Fase 2):\n",
      "ğŸ”¥ OFERTA! Compre <NUM> x zapatos Nike a <USD>99 <NUM> antes <USD>150 ğŸ‘Ÿ VÃ¡lido hasta el <NUM> / <NUM> / <NUM> ! Visita AtenciÃ³n EnvÃ­o gratis? ğŸ˜ƒ ModaDeportiva <NUM>\n",
      "\n",
      "Texto con mayÃºsculas normalizadas (Fase 3):\n",
      "ğŸ”¥ oferta! Compre <num> x zapatos Nike a <usd>99 <num> antes <USD>150 ğŸ‘Ÿ vÃ¡lido hasta el <num> / <num> / <num> ! visita atenciÃ³n envÃ­o gratis? ğŸ˜ƒ modadeportiva <num>\n",
      "\n",
      "Texto procesado (Pipeline completo):\n",
      "ğŸ”¥ oferta! Compre <num> x zapatos Nike a <usd>99 <num> antes <USD>150 ğŸ‘Ÿ vÃ¡lido hasta el <num> / <num> / <num> ! visita atenciÃ³n envÃ­o gratis? ğŸ˜ƒ modadeportiva <num>\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar modelos de spaCy para espaÃ±ol e inglÃ©s\n",
    "try:\n",
    "    nlp_es = spacy.load(\"es_core_news_md\")\n",
    "    nlp_en = spacy.load(\"en_core_web_md\")\n",
    "except OSError:\n",
    "    print(\"Error: Los modelos de spaCy no estÃ¡n instalados.\")\n",
    "    print(\"Necesitas ejecutar la celda anterior para descargarlos.\")\n",
    "\n",
    "# Diccionario de marcas personalizadas que queremos preservar\n",
    "# PodrÃ­a ser cargado desde un CSV en un caso real\n",
    "marcas_personalizadas = [\n",
    "    \"Nike\", \"Adidas\", \"Zara\", \"H&M\", \"Apple\", \"Samsung\", \"iPhone\", \n",
    "    \"Canon\", \"Sony\", \"Xiaomi\", \"MarketMind\"\n",
    "]\n",
    "\n",
    "def normalize_case(text):\n",
    "    \"\"\"FunciÃ³n para normalizar mayÃºsculas preservando nombres de marcas, productos y entidades geopolÃ­ticas.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "    text (str): Texto a normalizar (previamente limpiado y con nÃºmeros normalizados)\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto con mayÃºsculas normalizadas\n",
    "    \"\"\"\n",
    "    # Primero detectamos el idioma para usar el modelo adecuado\n",
    "    # Esta es una simplificaciÃ³n, para una aplicaciÃ³n real se usarÃ­a\n",
    "    # un detector de idioma mÃ¡s robusto\n",
    "    if any(word in text.lower() for word in ['el', 'la', 'los', 'las', 'en', 'con', 'para']):\n",
    "        nlp = nlp_es\n",
    "    else:\n",
    "        nlp = nlp_en\n",
    "        \n",
    "    # Tokenizamos el texto\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Identificamos las entidades que queremos preservar\n",
    "    entity_spans = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"PRODUCT\", \"LOC\", \"GPE\"]:\n",
    "            entity_spans.append((ent.start_char, ent.end_char, ent.text))\n",
    "            \n",
    "    # Identificamos hashtags y menciones\n",
    "    tokens = text.split()\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.startswith(\"#\"):\n",
    "            start_idx = text.find(token)\n",
    "            if start_idx >= 0:\n",
    "                entity_spans.append((start_idx, start_idx + len(token), token))\n",
    "    \n",
    "    # Buscamos marcas personalizadas en el texto\n",
    "    for marca in marcas_personalizadas:\n",
    "        start = 0\n",
    "        while True:\n",
    "            start_idx = text.lower().find(marca.lower(), start)\n",
    "            if start_idx < 0:\n",
    "                break\n",
    "            entity_spans.append((start_idx, start_idx + len(marca), marca))\n",
    "            start = start_idx + len(marca)\n",
    "            \n",
    "    # Convertir todo a minÃºsculas primero\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Reconstruir el texto preservando las entidades identificadas\n",
    "    result = list(text_lower)\n",
    "    for start, end, original in sorted(entity_spans, key=lambda x: x[0]):\n",
    "        for i in range(start, end):\n",
    "            if i < len(result):\n",
    "                result[i] = text[i]\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "# FunciÃ³n para el pipeline completo: limpieza + normalizaciÃ³n + casos\n",
    "def process_text_full(text):\n",
    "    \"\"\"Aplica el pipeline completo de procesamiento de texto: \n",
    "    limpieza + normalizaciÃ³n de nÃºmeros y unidades + normalizaciÃ³n de mayÃºsculas.\n",
    "    \n",
    "    ParÃ¡metros:\n",
    "    text (str): Texto crudo a procesar\n",
    "    \n",
    "    Returns:\n",
    "    str: Texto completamente procesado\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    normalized = normalize_text(cleaned)\n",
    "    case_normalized = normalize_case(normalized)\n",
    "    return case_normalized\n",
    "\n",
    "# Verificar con el ejemplo especÃ­fico\n",
    "ejemplo_especifico = \"ğŸ”¥Â¡OFERTA! Compre 2x zapatos Nike a $99.99 (antes $150) ğŸ‘Ÿ. Â¡VÃ¡lido hasta el 30/11/2023! Visita https://marketmind.com/oferta-nike. AtenciÃ³n @MariaP: Â¿EnvÃ­o gratis? ğŸ˜ƒ #ModaDeportiva2023.\"\n",
    "print(\"== VerificaciÃ³n Pipeline Completo ==\\n\")\n",
    "print(\"Texto original:\")\n",
    "print(ejemplo_especifico)\n",
    "\n",
    "print(\"\\nTexto limpio (Fase 1):\")\n",
    "cleaned = clean_text(ejemplo_especifico)\n",
    "print(cleaned)\n",
    "\n",
    "print(\"\\nTexto normalizado (Fase 2):\")\n",
    "normalized = normalize_text(cleaned)\n",
    "print(normalized)\n",
    "\n",
    "print(\"\\nTexto con mayÃºsculas normalizadas (Fase 3):\")\n",
    "case_normalized = normalize_case(normalized)\n",
    "print(case_normalized)\n",
    "\n",
    "print(\"\\nTexto procesado (Pipeline completo):\")\n",
    "print(process_text_full(ejemplo_especifico))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb1c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplo 1 ===\n",
      "Texto original:\n",
      "Â¿DÃ³nde estÃ¡ mi pedido? NÃºmero de orden: #456DEF. Llevan 7 dÃ­as sin actualizar.\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "dÃ³nde estÃ¡ mi pedido? nÃºmero de orden <num> def llevan <num> dÃ­as sin actualizar\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 2 ===\n",
      "Texto original:\n",
      "Best headphones ever! Bought for 129.95 USD on 11/11/2023. ğŸ§\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "best headphones ever! bought for <num> <usd>95 on <num> / <num> / <num> ğŸ§\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 3 ===\n",
      "Texto original:\n",
      "Achieved my fitness goal with this! Purchased 1x treadmill at $799.99. ğŸƒâ€â™‚ï¸\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "achieved my fitness goal with this! purchased <num> x treadmill at <usd>799 <num> ğŸƒ â™‚\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 4 ===\n",
      "Texto original:\n",
      "Me encanta este producto! Calidad superior, pero 150â‚¬ es caro. Link: http://ecomerce.test/item123. ğŸ‘ #Review\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "me encanta este producto! calidad superior pero <EUR>150 es caro Link <num> ğŸ‘ Review\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Ejemplo 5 ===\n",
      "Texto original:\n",
      "Slow shipping to Madrid. Expected in 10 days, arrived in 15. ğŸ˜•\n",
      "\n",
      "Texto procesado (pipeline completo):\n",
      "slow shipping to Madrid expected in <num> days arrived in <num> ğŸ˜•\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Probemos con algunos ejemplos aleatorios para verificar el funcionamiento completo del pipeline\n",
    "for i in range(5):\n",
    "    random_sample = random.choice(samples)\n",
    "    ejemplo = random_sample['input']\n",
    "    \n",
    "    print(f\"\\n=== Ejemplo {i+1} ===\")\n",
    "    print(\"Texto original:\")\n",
    "    print(ejemplo)\n",
    "    print(\"\\nTexto procesado (pipeline completo):\")\n",
    "    print(process_text_full(ejemplo))\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvWSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
